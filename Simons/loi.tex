% Copyright 2014 the authors.  All rights reserved.

% ## style guide:
% - nothing higher level than \paragraph{}
% - line break between sentences (that means you, O'Neil)
% - capitalize Collaboration
% - products and brands are \project{foo}

\documentclass[11pt]{article}
\usepackage{fancyheadings, color, hyperref}
\usepackage{tabto}
% hypertex insanity
  \definecolor{linkcolor}{rgb}{0,0,0.4}
  \hypersetup{
    colorlinks=true,        % false: boxed links; true: colored links
    linkcolor=linkcolor,    % color of internal links
    citecolor=linkcolor,    % color of links to bibliography
    filecolor=linkcolor,    % color of file links
    urlcolor=linkcolor      % color of external links
  }
% Margins and spaces
  \setlength{\oddsidemargin}{0in}
  \setlength{\topmargin}{0in}
  \setlength{\headsep}{0.20in}
  \setlength{\headheight}{0.25in}
  \setlength{\textheight}{9.00in}
  \addtolength{\topmargin}{-\headsep}
  \addtolength{\topmargin}{-\headheight}
  \setlength{\textwidth}{6.50in}
  \setlength{\parskip}{0.5ex}
% Headings and footing
  \renewcommand{\headrulewidth}{0pt}
  \pagestyle{fancy}
  \lhead{\textsf{Goodman, Hogg \& O'Neil: \textit{Making Astrophysical Inferences Tractable}}}
  \rhead{\textsf{\thepage}}
  \cfoot{}

%  \usepackage{mathpazo}
%    \usepackage{pdfpages}

\newcommand{\foreign}[1]{\textsl{#1}}
\newcommand{\etal}{\foreign{et~al.}}
\newcommand{\project}[1]{\textsl{#1}}

\newcommand{\hoggitem}{$\bullet$}
\newcommand{\bioindent}{\tabto{1.5in}}

\usepackage[margin=.95in]{geometry}
%\usepackage[margin=1.0in]{geometry}
\usepackage{url}

\renewcommand{\paragraph}[1]{\smallskip\par\noindent\textbf{{#1}:}}

\begin{document}\sloppy\sloppypar\thispagestyle{empty}

\begin{center}
\textbf{Simons Collaboration: Making Precise Astrophysical Inferences
Tractable}\\
\textit{Collaboration Director:} Jonathan Goodman (Mathematics, NYU)\\
\textit{Core PIs:} Jonathan Goodman, David W. Hogg (Physics, NYU),\\ and
Michael O'Neil (Mathematics, NYU)
% \textit{Collaborating faculty:} Tom Hou (Applied Mathematics, Caltech)
\end{center}
\smallskip

We propose a Simons Collaboration to develop new mathematical and computational 
methods for probabilistic inference and discovery in astrophysics.
Probabilistic inference was crucial for many recent discoveries,
including the unexpected abundance and distribution of
exoplanets found in the NASA \project{Kepler} satellite data.
The next steps involve systematic simultaneous hierarchical inference
and more detailed physical models, both of the objects being studied and of
the instruments (lenses, CCD arrays, etc.).
These tasks are simply not possible with current computational algorithms.

This Letter of Intent identifies several areas of mathematical research
that may enable more sensitive and powerful inference from astrophysical
data {\em and} areas of astrophysics research that may benefit from new
mathematics.
The Core PIs' recent contributions demonstrate that this particular
collaboration between applied mathematics and astrophysics can lead to
interesting new mathematics {\em as well as} to astronomical
discoveries.
One particular focus of this collaboration will be on addressing
common computational bottlenecks in inference and simulation.

The computational burden of large-scale probabilistic modeling and
Bayesian inference depends on the cost of a likelihood function
evaluation and the required number of such evaluations.
Accelerating likelihood function evaluations may involve developing new
fast numerical algorithms for large dense (but structured) linear systems
or differential equations, as well as cheap approximations (at perhaps a
cost in accuracy).
Improving on existing Markov Chain Monte Carlo (MCMC) methods would
result in fewer net likelihood evaluations per independent sample.
This may involve constructing schemes with affine invariance, learning
from rejected samples via response surface modeling, or using derivative
information and multi-level sampling.
Better algorithms will allow, and will be motivated by, more detailed and
physically accurate models for inference.
These models will include more realistic noise characterizations
that take into
account the non-linear physics of the source and the instrument.
%It also includes simultaneous complex inference ranging from groups of
%stars to populations of planets to the matter distribution of the
%universe.

In putting together the full proposal, we will grow our team to six or
eight PIs across several institutions, recruiting from the applied
mathematics and astrophysics communities.
Our proposal will also include creative ways to reach out to and involve
people in the math and astrophysics communities.

\paragraph{Our contributions}
The Core Team's work, driven by exoplanet questions,
has been quite productive.
We created a suite of novel MCMC samplers 
(Hou \etal, 2012; Foreman-Mackey \etal, 2013; Hou \etal,
2014), some of which are based on a self-tuning (affine-invariant)
ensemble proposal (Goodman \& Weare, 2010).
We produced the first reliable (quantitatively accurate with
computationally verified error bars) computations of certain fully
marginalized likelihoods, which allowed us to address a controversy
regarding the number of planets orbiting the star Gliese 581 (Hou \etal,
2014).
The resulting MCMC code written by Foreman-Mackey receives a dozen
citations per month across a wide range of physics disciplines.

We created fast (nearly-optimal), high-accuracy linear algebra
routines for calculating the inverse and determinant of the large-scale
dense covariance matrices which appear in Gaussian processes
(Ambikasaran \etal, 2014).
The resulting code can invert million-by-million matrices
accurately on a laptop in $\sim 30$sec and is now being used by
several researchers in varying fields.
These tools allowed us to address a disagreement concerning properties
of some planetary orbits around highly variable stars (Barclay \etal,
2014).
We also produced the first fully probabilistic hierarchical inference of
the exoplanet population (Foreman-Mackey \etal, 2014) based on an
earlier importance-sampling method of ours (Hogg \etal, 2010).
This hierarchical inference yielded different (by a factor of seven for
the abundance of Earth-like planets) answers than previous inferences,
due in part to far more responsible use of the data (propagating noise)
and far less restrictive assumptions.

Additionally, we have been using these and other tools to study
weak-lensing distortions ($\sim 0.1\%$), which are hard to find
due to the complex morphologies of galaxies.
Our biggest contribution so far is a system
that can compute the stochastic variation of the \emph{pixels} of the
imaging from the telescope in terms of standard cosmological parameters
(Schneider \etal, in prep.).
The pixel-level component of this project involves image modeling,
where we have developed a general and flexible framework.
Our open-source code, \project{The~Tractor} (Lang \etal,
in prep.) is now being used for cosmological projects by several other groups.
We have begun to apply these ideas and techniques to 
improve photometry in \project{K2}, the
post-\project{Kepler} mission in which the spacecraft is unable to point
as precisely as in the original design (Montet \etal, in prep).

We have also been investigating more data-driven camera models.
Working with Rob Fergus~(NYU), we have built
{\em effective models} for complex astronomical 
imagers (Fergus \etal, 2014).
These made it possible to perform infrared spectroscopy of several 
young exoplanets (Oppenheimer \etal, 2014).
Furthermore, with Bernhard Sch\"olkopf (MPI-IS), we have created
multi-star models of NASA \project{Kepler} light-curves using ideas from
causal inference:
by modeling many star fluctuations at once, we are able to separate
common fluctuations due to spacecraft-induced variability from idiosyncratic
star fluctuations that contain transit information (Wang \etal, in prep.;
Foreman-Mackey \etal, in prep.).

\paragraph{New Directions}
We have identified many new mathematical and astrophysical avenues for
research in the Collaboration.
The details of what we finally propose will depend precisely on the
PIs that we recruit (see below) and the joint abilities that we
identify among them.
Here, for example, are several directions that we have already
identified as clearly promising.

\textbf{Effective models of astronomical instruments:}
Simultaneous modeling of many (or all) of the individual images contained in
a telescope's [[[field of view WRONG PHRASE]]] 
may allow us to distinguish variability due to the instrument from
variability of the objects themselves.  
This should make it possible to identify weak photometric or spectroscopic
signals with much more confidence.

\textbf{First principles camera simulation:} 
There has been a lot of work aimed at the accurate forward simulation of the
optics of complex telescopes.
We bring to this endeavor several fast numerical algorithms for 
Maxwell's equations, new methods in 
high-frequency asymptotics, and the ability to calibrate complex systems 
to data using Bayesian Monte Carlo.

\textbf{Noise models for stochastic variable stars:}
Signals from stars fluctuate because of asteroseismology 
(damped, driven normal modes), stochastic surface convection, star
spots, etc.
A Bayesian noise model built on this physics will make it possible to 
find ever smaller exoplanet signals with confidence.
Normal-mode noise translates directly into Gaussian processes 
for which we have very fast computational tools.
In the star-spot and convection models, it also appears that there may
be stationary, non-trivial processes that can be developed and made
tractable.

\textbf{New MCMC methods:}
We have several ideas for improved MCMC samplers.
One, which is partly developed, is an MCMC version of the Gauss-Newton
method for nonlinear least squares.
This sampler uses derivative information to realize affine invariance,
and is augmented by a stochastic step size control algorithm that satisfies
detailed balance.
There are indications that improved affine invariant samplers depend on 
controlling the different ways metrics can degenerate.
However, the theory of affine invariant samplers is subtle in part
because they
lack compactness properties of traditional $\mathcal O(n)$ invariant 
Metropolis
samplers.

\textbf{Posterior likelihood modeling:}
Using ideas from experimental design and response surfaces, we plan to
model posterior log-likelihood surfaces using
Gaussian processes.
Numerical experiments show that our technique is able to
identify some highly non-Gaussian models in two-dimensions using 
as few as
fifty likelihood evaluations.

\textbf{Novel analysis-based methods for dense linear algebra:}
The Core Team has already succeeded in producing algorithms for Gaussian
processes which scale nearly-linearly in the dimension of the likelihood
function.
Further improvements to this algorithm can be made, namely optimizations
for distributed computing environments, improvements in the accuracy
which rely on the analytic formulation of the covariance kernel, and
extensions to hierarchical probabilistic structures.

\textbf{Hierarchical models of exoplanet populations:}
The Core-Team work on making hierarchical problems tractable has
only scratched the surface of what might be possible going forward.
It is now (in part because of the Core Team's influence) becoming
understood in the astrophysics community that hierarchical inference
is required in order to propagate catalog-level or pixel-level noise to
population-level inferences.
Efficient and robust samplers for hierarchical models would be widely 
applicable in
and outside of astrophysics.

\textbf{Marginalization of the cosmological density field:} 
It now appears possible to create flexible representations of the
two-point autocorrelation function relevant to cosmology, including
the general large-scale structure covariance and the baryon
acoustic feature (Eisenstein \etal, 2005).
Cosmological inferences, which currently seek to estimate the two-point 
function, could instead infer and marginalize {\em directly}
over the density field itself.
Direct field models allow for more realistic noise modeling that does
not rely
on assumptions of Gaussianity, which may be unwarranted.
Such massive inference is impractical without several new computational
methods
that are goals of this Collaboration.

\paragraph{Collaboration personnel and budget}
The three Core PIs for this proposal are Goodman, Hogg, and O'Neil.
Current graduate student Foreman-Mackey (NYU), who expects to finish
this spring, will---if we can retain him---continue as a postdoctoral
fellow.
Tom Hou (Caltech) has agreed to join the collaboration.
He is a pioneer in multi-level sampling methods.
We plan for the full proposal to recruit two to four more tenured,
tenure track, or equivalent level members at other institutions.  Our
current list of recruiting candidates includes: John
Johnson (Harvard), Mario Juric (UW), Phil Marshall (KIPAC), and Bernhard
Sch\"olkopf (MPI-IS).
We will plan to hire eight postdoctoral fellows and support eight
graduate students, in equal proportion in mathematics and astrophysics.
[[[The Collaboration will leverage the NYU Center for Data Science. WHAT
DOES THIS MEAN???]]]
We estimate a final budget of approximately 2.1M USD per year,
based on a total of eight PIs and their approximate commitments.

\paragraph{Collaboration plan and community involvement}
Our research and outreach activities will lead to a mutually beneficial
transfer of knowledge from computational mathematicians to
astrophysicists, and vice versa.
Externally, one of the distinctive features of our research is the way
in which we interact, and plan to interact, with the larger mathematical
and astrophysics communities.
In addition to an annual Collaboration meeting in New York at the Simons
Foundation---where we would invite not just our team but relevant
outsiders---we expect to engage the broader community through \emph{Hack
Days} and tutorials at professional meetings, especially the AAS and the 
SIAM meetings.
This approach has already proven to be extremely successful with regard
to the impact of our MCMC and Gaussian process software packages.

Equally important, we intend for all work in the Collaboration to
proceed along a fully \emph{open} model, as the work of the Core Team
already exemplifies.
We expect that a significant part of our community involvement will
proceed through the sharing of software packages, as well as projects in
progress.
In particular, all the publications from the Collaboration would be
supported by open-source software with liberal licensing (MIT or similar).


\end{document}
